{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('3.7.9': pyenv)"
  },
  "interpreter": {
   "hash": "fd1c2548c0081c4b872ff77168d29b2aa7e0f3b5da3451811b97c10e6da6d663"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Particle-flow interaction\n",
    "\n",
    "\n",
    "We split the particle and flow solvers into separate ranks similar to the approach taken in Thari et al's [ATEL paper](./Resources.ipynb#atel):\n",
    "\n",
    "![Solver structure](./images/solver-structure.png)\n",
    "<img src=\"./images/solver-structure.png\">\n",
    "\n",
    "## Additional source terms for the flow solver, provided by the particle solver\n",
    "The Lagrangian (particle) simulation influences the flow solver by providing addition source terms for the differential equations in the flow solver.\n",
    "These source terms are:\n",
    "* $\\frac{dm_d}{dt}$ ($\\dot{m_d}$), which is added as a source term in the Mass Continuity Equation\n",
    "* $\\frac{d \\omega_Z}{dt}$ ($\\dot{\\omega_Z}$), which is added as a source term in the Mixture Fractioon equation\n",
    "* $S_{i}$, added to the Momentum Equation\n",
    "* $Q_{d}$, added to the Energy Equation\n",
    "\n",
    "Formulas for these are given in Thari's paper.\n",
    "\n",
    "\n",
    "## Flow field values for the particle solver, provided by the flow solver\n",
    "TODO!\n",
    "\n",
    "# Synchronisation and timestepping\n",
    "In the ATEL approach, we need to synchronise flow field values\n",
    "In other words, the particle solver is using flow field values in the past. This does not drastically affect the outcome of the simulation, but\n",
    "does allow us to parallelise the problem better.\n",
    "\n",
    "In the ATEL approach, the synchronisation uses one-sided MPI comminicaction between shared memory regions on a single compute node, so that solver rank A\n",
    "can read values written by the solver on rank B, without communication bottlenecks. In MiniCombust, we use a slightly different approach and\n",
    "duplicate the flow field values in the particle solver, and the source term fields in the flow solver, i.e. we use a true distributed memory approach.\n",
    "This allows us the flexibility to have particle ranks that gather flow values from other, possibly distant ranks, and allows much more flexible implementation\n",
    "of different load balancing strategies."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "\n",
    "from collections import namedtuple\n",
    "from typing import Map\n",
    "\n",
    "\"\"\"\n",
    "NOTE: The spray solver decomposition is not necessarily the same as the particle solver decomposition!\n",
    "So when we update the spray field, we need to know which cell's spray is calculated by which rank\n",
    "And we need to know which cell's flow is calculated by which rank\n",
    "\"\"\"\n",
    "class SpraySolver:\n",
    "    flow_values = {\n",
    "        'turbulence_field': None,\n",
    "        'combustion_field': None,\n",
    "        'spray_field': None,\n",
    "        'flow_field': None,\n",
    "    }\n",
    "\n",
    "    def update_spray_field(self):\n",
    "        \"\"\"\n",
    "        Copies in the new grid source terms from the particle solver\n",
    "        We COPY rather than use Read-only access to a Window as in ATEL, to allow\n",
    "        the flexibility of different load balancing strategies\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def solve_combustion_equations(self):\n",
    "        \"\"\"\n",
    "        transport of mixture fraction\n",
    "        progress variable\n",
    "        variance of mixture fraction\n",
    "        variance of progress variable\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def update_combustion_field(self):\n",
    "        \"\"\"\n",
    "        interpolate thermomech state of cell from \n",
    "        mixture fraction and progress variable, looking up\n",
    "        against FGM tables\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def solve_turbulence_equations(self):\n",
    "        \"\"\"\n",
    "        turbulent kinetic energy\n",
    "        dissipation\n",
    "        enthalpy?\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def update_turbulence_field(self):\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def solve_flow_equations(self):\n",
    "        \"\"\"\n",
    "        conservation of mass\n",
    "        conservation of momentum\n",
    "        conservation of energy\n",
    "        pressure correction\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def timestep(self):\n",
    "        self.update_spray_field() # syncrhonising with particle solver\n",
    "        self.solve_combustion_equations()\n",
    "        self.update_combustion_field()\n",
    "        self.solve_turbulence_equations()\n",
    "        self.update_turbulence_field()\n",
    "        self.solve_flow_equations()\n",
    "        self.update_flow_field()\n",
    "\n",
    "\n",
    "\n",
    "class ParticleSolver:\n",
    "    Particle = namedtuple('Particle', ['coords', 'mass', 'diameter', 'rate_of_mass_change', ''])\n",
    "\n",
    "    spray_values = {\n",
    "        'flow_field': None,\n",
    "        'particles': Map[int, Particle]\n",
    "    }\n",
    "\n",
    "    derived_additional_source_terms = {\n",
    "        'dm_d_dt' : None, # for mass equation\n",
    "        'domega_Z_dt': None, # for mixture fraction equation\n",
    "        'S_i,d': None, # for momentum equation\n",
    "        'Q_d': None # for energy equation\n",
    "    }\n",
    "\n",
    "    def update_flow_field(self):\n",
    "        \"\"\"\n",
    "        Copies in the velocity for cells from the flow solver\n",
    "        This will be used in the calculation of the 'virtual force' in solve_spray_equations\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def particle_release(self):\n",
    "        \"\"\"\n",
    "        At spray injection locations, new droplets are injected with diameter from\n",
    "        Rosin-Rammler distribution, and corresponding properties: velocity, \n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def solve_spray_equations(self):\n",
    "        \"\"\"\n",
    "        evaporation: update mass\n",
    "        drag force\n",
    "        virtual force\n",
    "        body force \n",
    "        solve velocity\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "\n",
    "    def update_particle_positions(self):\n",
    "        \"\"\"\n",
    "        Move particle according to calculated velocity and current position\n",
    "        \"\"\"\n",
    "        particles.positions += particles.velocities * timestep_size\n",
    "\n",
    "        pass\n",
    "\n",
    "    def update_spray_source_terms(self):\n",
    "        \"\"\"\n",
    "        For each cell in domain we calculate\n",
    "            dm_d_dt = sum_over_all_particles(dm_d/d_t for particle)\n",
    "            domega_Z_dt = dm_d_dt\n",
    "            `S_i,d` =  sum_over_all_particles(d(droplet_mass * droplet_velocity)/dt)\n",
    "            `Q_d` = sum_over_all_particles(heat_transferred_from_air_to_fuel - heat_absorbed_through_evaporation)\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "\n",
    "    def map_source_terms_to_grid(self):\n",
    "        \"\"\"\n",
    "        Copy source terms to grid cells ready for transfer to spray solver\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def timestep(self):\n",
    "        self.update_flow_field() # synchronising with flow solver\n",
    "        self.particle_release()\n",
    "        self.solve_spray_equations()\n",
    "        self.update_particle_positions()\n",
    "        self.update_spray_source_terms()\n",
    "        self.map_source_terms_to_grid()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "cannot import name 'Map' from 'typing' (/Users/work/.pyenv/versions/3.7.9/lib/python3.7/typing.py)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6n/43v9c5zn7h325hymgd1f43500000gp/T/ipykernel_39424/3100126803.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnamedtuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \"\"\"\n\u001b[1;32m      5\u001b[0m \u001b[0mNOTE\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mspray\u001b[0m \u001b[0msolver\u001b[0m \u001b[0mdecomposition\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnecessarily\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mparticle\u001b[0m \u001b[0msolver\u001b[0m \u001b[0mdecomposition\u001b[0m\u001b[0;31m!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Map' from 'typing' (/Users/work/.pyenv/versions/3.7.9/lib/python3.7/typing.py)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Interpolation between cells and particles for flow field values\n",
    "\n",
    "When we read the field value (e.g. pressure) for a cell that a particle is in, we get inaccuraccies if we only use the cell centre value and don't compensate for the particle's position in the cell.\n",
    "As a correction, we first interpolate the field to values at the cell nodes. Then, when calculating the value for a particle, we interpolate the nodal values of the cell to the particle's position.\n",
    "\n",
    "## Interpolation of cell centre values to nodal values\n",
    "We correct using the gradient of the field and the distance from the node to the cell centre, and normalising nodal values based on `Dolfyn: opendx.f90:: InterpolateData`\n",
    "For non-scalar fields (velocity), this is done _per dimension_"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "def interpolate_data(Φ: NDArray[T]) -> NDArray[T]:\n",
    "    \"\"\"\n",
    "    Interpolates data from scalar field Φ at cell centres to values at the node coordinates of each cell\n",
    "    NOTE We only do Dolfyn's 'Mode 0' interpolation - i.e. we DO use boundary face values\n",
    "\n",
    "    phi: len num_cells + num_boundaries, 1D  SOME SCALAR FIELD\n",
    "\n",
    "    Dolfyn: opendx.f90:: InterpolateData\n",
    "    \"\"\"\n",
    "    dΦdX = gradient(Φ)\n",
    "    nodal_values_of_Φ = np.zeros((num_nodes, ), dtype=T)\n",
    "    nodal_counter = np.zeros((num_nodes, ), dtype=int)\n",
    "\n",
    "    # Project each cells value to the faces' nodes by using the gradient and distance from the node\n",
    "    for cell in Cells:\n",
    "        cell_coordinates = cell.coordinates()\n",
    "        cell_φ = Φ[cell.id()]\n",
    "        cell_dφ = dΦdX[cell.id()]\n",
    "        for face in cell.faces():\n",
    "            for node in face.nodes():\n",
    "                ds = node.coordinates() - cell_coordinates\n",
    "                nodal_values_of_Φ[node.id()] += cell_φ + np.dot(cell_dφ, ds)\n",
    "                nodal_counter[node.id()] += 1\n",
    "\n",
    "    # now we take into account boundaries\n",
    "    for boundary in Boundaries:\n",
    "        if boundary.region().type() != SYMMETRIC_PLANE:\n",
    "            for node in enumerate(boundary.face().nodes()):\n",
    "                nodal_values_of_Φ[node.id()] += Φ[Cells.num_cells + boundary.id()]\n",
    "                nodal_counter[node.id()] += 1\n",
    "        \n",
    "    # Normalise nodal values by how many times node was incremented\n",
    "    for node in Nodes:\n",
    "        if nodal_counter[node.id()] > 0:\n",
    "            nodal_values_of_Φ[node.id()] /= nodal_counter[node.id()]\n",
    "    \n",
    "    return nodal_values_of_Φ"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Interpolating from nodal values to a corrected value of a field for the particle\n",
    "Weight by the normalised inverse square distance of the particle to each node of the cell. `Dolfyn: particles.f90::ParticleGetVelocity`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# This should work for 3D (e.g. velocity) and 1D (e.g. scalar) values\n",
    "# because of numpy broadcasting rules\n",
    "def get_corrected_value_for_particle_in_cell(position: T3, cell_node_ids: NDArray[int], values_at_all_nodes: NDArray[T], all_node_coords: NDArray[T]) -> T3:\n",
    "    \"\"\"\n",
    "    Rather than using cell-centered scalar value (e.g temperature), we calculate the cell value for each particle by using the \n",
    "    values at the nodes of the cell (as determined by interpolate_data above), and weighting by the distance of the particle to each node\n",
    "\n",
    "    Dolfyn: particles.f90::ParticleGetVelocity\n",
    "    \"\"\"\n",
    "    epsilon = 1e-12 # a small value, to avoid division by 0 \n",
    "    diff_particle_to_nodes = position - all_node_coords[cell_nodes, :] # Delta from particle position to each node's position\n",
    "    node_weights = np.dot(diff_particle_to_nodes, diff_particle_to_nodes) # square distance\n",
    "    node_weights = 1. / (node_weights + epsilon) # inverse\n",
    "    total = sum(node_weights) # total weight\n",
    "\n",
    "    node_weights /= total # normalise weights\n",
    "    return np.sum(node_weights * values_at_all_nodes[cell_node_ids,:], ax=0) # sum weighted node velocities\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Interpolating from Particle values in a cell, to a cell-centred source term\n",
    "In each cace, we simply sum the corresponding values for each particle in the cell"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def particle_rate_of_mass(particle):\n",
    "    # Todo Do we calculate this term as part of particle_intercace?\n",
    "    pass\n",
    "\n",
    "def momentum(particle):\n",
    "    # Todo do we calculate this term as part of particle_interface?\n",
    "    \"\"\" d/dt of particle.mass * particle.velocity\"\"\"\n",
    "    pass\n",
    "\n",
    "def energy(particle):\n",
    "    return particle.heat_transferred_from_air_to_fuel - particle.heat_absorbed_through_evaporation\n",
    "\n",
    "\n",
    "# ...\n",
    "\n",
    "for cell in Cells:\n",
    "    particles_in_cell = filter(lambda p: p.current_cell() == cell, Particles)\n",
    "    rate_of_mass_source_term[cell.id()] = sum(particle_rate_of_mass(particle) for particle in particles_in_cell)\n",
    "    momentum_source_term[cell.id()] = sum(momentum(particle) for particle in particles_in_cell)\n",
    "    energy_source_term[cell.id()] = sum(energy(particle) for particle in particles_in_cell)\n",
    "mixture_fraction_source_term[:] = rate_of_mass_source_term[:]\n",
    "# ...\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'Cells' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6n/43v9c5zn7h325hymgd1f43500000gp/T/ipykernel_39424/4098699771.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCells\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mparticles_in_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParticles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mrate_of_mass_source_term\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparticle_rate_of_mass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparticle\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparticle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparticles_in_cell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Cells' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}